{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenGeoHub Summer School 2022 - Introduction to GeoPandas and its Python ecosystem\n",
    "\n",
    "**Martin Fleischmann**\n",
    "\n",
    "<sup>1</sup>Geographic Data Science Lab, University of Liverpool, UK<br>\n",
    "<sup>2</sup>Urban and Regional Laboratory, Charles University, CZ<br>\n",
    "<sup>3</sup>UrbanDataLab AG, ZÃ¼rich, CH\n",
    "\n",
    "31/08/2022, Siegburg\n",
    "\n",
    "## Setup\n",
    "\n",
    "Follow the Readme to set-up the environment correctly. You should have these packages installed:\n",
    "\n",
    "```\n",
    "- geopandas\n",
    "- dask-geopandas\n",
    "- pyogrio\n",
    "- pyarrow\n",
    "- python-graphviz\n",
    "- esda\n",
    "- momepy\n",
    "- libpysal\n",
    "- dask-labextension # optionally, if using JupyterLab\n",
    "```\n",
    "\n",
    "## What is GeoPandas\n",
    "\n",
    "Let's have a look what the documentation says.\n",
    "\n",
    "GeoPandas, as the name suggests, extends the popular data science library [pandas](https://pandas.pydata.org) by adding support for geospatial data.\n",
    "\n",
    "The core data structure in GeoPandas is the `geopandas.GeoDataFrame`, a subclass of `pandas.DataFrame`, that can store geometry columns and perform spatial operations. The `geopandas.GeoSeries`, a subclass of `pandas.Series`, handles the geometries. Therefore, your `GeoDataFrame` is a combination of `pandas.Series`, with traditional data (numerical, boolean, text etc.), and `geopandas.GeoSeries`, with geometries (points, polygons etc.). You can have as many columns with geometries as you wish; there's no limit typical for desktop GIS software.\n",
    "\n",
    "![geodataframe schema](fig/dataframe.svg)\n",
    "\n",
    "Each `GeoSeries` can contain any geometry type (you can even mix them within a single array) and has a `GeoSeries.crs` attribute, which stores information about the projection (CRS stands for Coordinate Reference System). Therefore, each `GeoSeries` in a `GeoDataFrame` can be in a different projection, allowing you to have, for example, multiple versions (different projections) of the same geometry.\n",
    "\n",
    "Only one `GeoSeries` in a `GeoDataFrame` is considered the _active_ geometry, which means that all geometric operations applied to a `GeoDataFrame` operate on this _active_ column.\n",
    "\n",
    "But when we talk about GeoPandas, we first have to talk about pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is pandas?\n",
    "\n",
    "Once again, the best place to ask this question is the documentation.\n",
    "\n",
    "> `pandas` is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "What that means in practice? Pandas provides two key data structures - a `Series` and a `DataFrame`.\n",
    "\n",
    "![dataframe](fig/01_table_dataframe.svg)\n",
    "\n",
    "### Reading and writing\n",
    "\n",
    "We can start quickly illustrating pandas in practice by reading some files. While pandas can read many file formats, we can keep it simple and read a CSV.\n",
    "\n",
    "![io](fig/02_io_readwrite.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with some demographic characteristics in Liverpool, borrowed from a [Geographic Data Science](https://darribas.org/gds_course/content/bB/lab_B.html) course by [Dani Arribas-Bel](http://twitter.com/darribas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop = pandas.read_csv(\n",
    "    \"https://darribas.org/gds_course/content/data/liv_pop.csv\",  # path to the file\n",
    "    index_col=\"GeographyCode\",  # column to use as an index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how the data look like by simply typing its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column or row is a Series object, which we can access based on name, location or other means.\n",
    "\n",
    "![subset](fig/03_subset_columns_rows.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop[\"Middle East and Asia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop[\"Middle East and Asia\"] > 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop[liv_pop[\"Middle East and Asia\"] > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop.loc[\n",
    "    liv_pop[\"Middle East and Asia\"] > 500, [\"Africa\", \"The Americas and the Caribbean\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also combine columns to create a new one. What is the total population of each LSOA?\n",
    "\n",
    "![new column](fig/05_newcolumn_2.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = liv_pop.sum(axis=1)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop[\"Total\"] = total\n",
    "liv_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also quickly visualize the data. (But not on a map yet, that is where GeoPandas comes in.)\n",
    "\n",
    "![plot](fig/04_plot_overview.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop[\"Total\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop.plot.scatter(\"Africa\", \"Middle East and Asia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's go back to GeoPandas!**\n",
    "\n",
    "If you look again at the diagram shown above (and here once again), you now undestand that both `index` and `data` are a practically a `pandas.DataFrame`. But what else is happenning there?\n",
    "\n",
    "## The pieces we bring together\n",
    "\n",
    "Any software that has an ambition to complexely deal with geospatial data needs to cover four aspects:\n",
    "\n",
    "- *data*\n",
    "    - We just learned that this part is covered by `pandas`.\n",
    "- *geometry*\n",
    "    - Handling of the actual geometries and operations on them. In FOSS, there is one leading engine, `GEOS`, but given it is written in C++, we need a Python wrapper. That is called `shapely`.\n",
    "- *projections*\n",
    "    - We need to know which place on the Earth (or other planet) each coordinates refer to. That is what projections, or Coordinate Reference Systems (CRS), take care of. The main FOSS engine here is `PROJ`, again written in C++ and in Python wrapped by `pyproj`.\n",
    "- *reading and writing files*\n",
    "    - Geospatial world knows a lot of file formats to store the data, from Shapefile and GeoJSON to GeoParquet. The best way to read and write into them is to use `GDAL/OGR`, another C++ library, which is avaliable either via `fiona` or recently via `pyogrio`.\n",
    "\n",
    "![ecosystem diagram](fig/ecosystem.jpg)\n",
    "\n",
    "Let's see all of them in action within GeoPandas.\n",
    "\n",
    "## GeoPandas in action\n",
    "\n",
    "First, we need to read some data.\n",
    "\n",
    "### Reading files\n",
    "\n",
    "Assuming you have a file containing both data and geometry (e.g. GeoPackage, GeoJSON, Shapefile), you can read it using `geopandas.read_file()`, which automatically detects the filetype and creates a `GeoDataFrame`. This can use either `fiona` or `pyogrio` as an engine (as of GeoPandas 0.11) interfacing GDAL/OGR to do the heavy lifting. We use `pyogrio` as a newer, faster option.\n",
    "\n",
    "We will again borrow data from the [GDS course](https://darribas.org/gds_course/content/bC/lab_C.html#cities) we used before. This time we load the boundaries of Spanish cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "\n",
    "cities = geopandas.read_file(\"https://ndownloader.figshare.com/files/20232174\")\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing files\n",
    "\n",
    "To write a `GeoDataFrame` back to file use `GeoDataFrame.to_file()`. The file format automatically inferred from the suffix, but you can specify your own with the `driver` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.to_file(\"cities.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometries\n",
    "\n",
    "Geometries within the *geometry* column are `shapely` objects. GeoPandas itself is not creating the object but leverages the existing ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cities.geometry.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.geometry.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.geometry.loc[0].wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But without an assigned CRS, we don't know where on the Earth this shape lies. Therefore, each geometry column has (optionally) assigned one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cities.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the whole ecosystem comes together.\n",
    "\n",
    "### Simple accessors and methods\n",
    "\n",
    "Now we have our `GeoDataFrame` and can start working with its geometry. \n",
    "\n",
    "Since there was only one geometry column in the New York Boroughs dataset, this column automatically becomes the _active_ geometry and spatial methods used on the `GeoDataFrame` will be applied to the `\"geometry\"` column.\n",
    "\n",
    "#### Measuring area\n",
    "\n",
    "To measure the area of each polygon (or MultiPolygon in this specific case), access the `GeoDataFrame.area` attribute, which returns a `pandas.Series`. Note that `GeoDataFrame.area` is just `GeoSeries.area` applied to the _active_ geometry column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"area\"] = cities.area\n",
    "cities[\"area\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting polygon boundary and centroid\n",
    "\n",
    "To get the boundary of each polygon (LineString), access the `GeoDataFrame.boundary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"boundary\"] = cities.boundary\n",
    "cities[\"boundary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have saved boundary as a new column, we now have two geometry columns in the same `GeoDataFrame`.\n",
    "\n",
    "We can also create new geometries, which could be, for example, a buffered version of the original one (i.e., `GeoDataFrame.buffer(10)`) or its centroid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"centroid\"] = cities.centroid\n",
    "cities[\"centroid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring distance\n",
    "\n",
    "We can also measure how far each centroid is from the first centroid location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_point = cities[\"centroid\"].iloc[0]\n",
    "cities[\"distance\"] = cities[\"centroid\"].distance(first_point)\n",
    "cities[\"distance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `geopandas.GeoDataFrame` is a subclass of `pandas.DataFrame`, so we have all the pandas functionality available to use on the geospatial dataset â we can even perform data manipulations with the attributes and geometry information together.\n",
    "\n",
    "For example, to calculate the average of the distances measured above, access the 'distance' column and call the mean() method on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"distance\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making maps\n",
    "\n",
    "GeoPandas can also plot maps, so we can check how the geometries appear in space. To plot the active geometry, call `GeoDataFrame.plot()`. To color code by another column, pass in that column as the first argument. In the example below, we plot the active geometry column and color code by the `\"area\"` column. We also want to show a legend (`legend=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.plot(\"area\", legend=True, figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Other resources for plotting\n",
    "\n",
    "Want to know more on static plots? Check [this chapter](https://darribas.org/gds_course/content/bC/lab_C.html#styling-plots) of the GDS course or [the GeoPandas documentation](https://geopandas.org/en/stable/docs/user_guide/mapping.html).\n",
    "</div>\n",
    "\n",
    "You can also explore your data interactively using `GeoDataFrame.explore()`, which behaves in the same way `plot()` does but returns an interactive map instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.explore(\"area\", legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching the active geometry (`GeoDataFrame.set_geometry`) to centroids, we can plot the same data using point geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities.set_geometry(\"centroid\")\n",
    "cities.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also layer both `GeoSeries` on top of each other. We just need to use one plot as an axis for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cities[\"geometry\"].explore()\n",
    "cities[\"centroid\"].explore(m=m, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the active geometry back to the original `GeoSeries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities.set_geometry(\"geometry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial join\n",
    "\n",
    "One of he most typical geospatial tasks is a spatial join. Let's try to figure out which of these cities fall into Catalonia region and which province they belong to.\n",
    "\n",
    "First, we need a data representing Catalonia. We get one directly from the Catalonian open data portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia = geopandas.read_file(\n",
    "    \"https://analisi.transparenciacatalunya.cat/api/geospatial/ghr8-wp3h?method=export&format=Shapefile\",\n",
    ")\n",
    "catalonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the CRS, because for spatial join, we need to be sure that both GeoDataFrames are using the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this one is different, we can re-project the geometries to the CRS of `cities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia = catalonia.to_crs(cities.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do the spaital join using the `sjoin` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia = cities.sjoin(catalonia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia.explore(\n",
    "    \"nom_prov\",\n",
    "    tiles=\"Stamen Toner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since GeoDataFrames are still based on pandas DataFrames, we can readily use pandas functionality, like `groupby` on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia.groupby(\"nom_prov\").area.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ecosystem\n",
    "\n",
    "We can now move beyond GeoPandas, because while being useful itself, its main benefit is that it enables other to build on top of robust basis. We can take an example of PySAL, Python Spatial Analysis Library. PySAL is a federation of 21 individual packages covering everything from basic spatial weights matrices to spatial regression, optimisation, point pattern analysis or dasymetric mapping.\n",
    "\n",
    "Today, we will look at two of them to learn how to work with spatial weights and how to measure local index of spatial autocorrelatoin (LISA).\n",
    "\n",
    "Let's go back to our LSOA-based data from Liverpool. This time, we load the geometries using geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa = geopandas.read_file(\n",
    "    \"https://darribas.org/gds_course/content/data/liv_lsoas.gpkg\",\n",
    ")\n",
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial weights\n",
    "\n",
    "Spatial weights can be created in many ways based on many conditions. We are now intersted in the most common one - contiguity. We simply want to encode, which geometries are neighbours of which.\n",
    "\n",
    "To generate such a matrix, we can use the `weights` module of `libpysal` and its `Queen` contiguity implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal import weights\n",
    "\n",
    "w_queen = weights.Queen.from_dataframe(liv_lsoa, idVariable=\"LSOA11CD\")\n",
    "w_queen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have used the LSOA code to encode the spatial weights. To make it a bit easier below, let's set the same variable as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa = liv_lsoa.set_index(\"LSOA11CD\")\n",
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can explore what `w_queen` object actually contains. We can pick one LSOA, say `E01006690` and check its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen[\"E01006690\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number `1.0` encodes the strength, because weights can be more complex than simple boolean is neighbor or not. It can potentially be weighted based on the lenght of the common boundary.\n",
    "\n",
    "We can also quickly check how many neighbours it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.cardinalities[\"E01006524\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if it is more or less than the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.mean_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check this on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa = \"E01006690\"\n",
    "\n",
    "m = liv_lsoa.loc[[lsoa]].explore(color=\"red\")\n",
    "liv_lsoa.loc[w_queen[lsoa].keys()].explore(m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remember that we also had some data for these areas. Let's compare the two data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One has geometries but no data, the other has data but no geometries. But both share the LSOA code we can use to merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa = liv_lsoa.merge(liv_pop, left_on=\"LSOA11CD\", right_on=\"GeographyCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial lag\n",
    "\n",
    "One of the very useful things we can do with spatial weights is to calculate a spatial lag. That is, in principle, a mean of values from neighbouring geometries.\n",
    "\n",
    "We can measure it easily using `lag_spatial` function. But before that, we need to transform the weights so the all weights (the numbers) for each geometry sum up to one. Otherwise we would measure the sum of instead of mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.transform = \"R\"\n",
    "\n",
    "w_queen_score = weights.lag_spatial(w_queen, liv_lsoa[\"Middle East and Asia\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen_score[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign it to the dataframe as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa[\"Middle East and Asia lagged\"] = w_queen_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moran plot\n",
    "\n",
    "With the spatial lag, we can start asking some deeply spatial questions. Like, is there a spatial autocorellation? The simplest way of getting a sense on that is to plot the original variable against its spatial lag, so called Moran plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.plot.scatter(\n",
    "    \"Middle East and Asia\", \"Middle East and Asia lagged\", figsize=(8, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is a relationship between the two, we can assume spatial autocorellation of the variable. And here it seems that there is a strong one.\n",
    "\n",
    "### LISA\n",
    "\n",
    "We can explore that further, using the Local Index of Spatial Autocorellation (LISA), implemented in another of PySAL's packages called `esda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran_Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do the actual measuring, we should normalise the values as some of the LSOAs have larger total population than the others and it would skew the output. We can rather look at proportions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa[\"Middle East and Asia proportion\"] = (\n",
    "    liv_lsoa[\"Middle East and Asia\"] / liv_lsoa[\"Total\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our existing spatial weights, pass the variable and mesure LISA based on Moran's I using the `Moran_Local` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc = Moran_Local(liv_lsoa[\"Middle East and Asia proportion\"], w_queen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what do we have here. A LISA quadrant encoding if the geometry has high values and is surrounded by other of high values or any other combination of high and low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc.q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a simulated P value indicating significance of the result for each geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is enough for us to plot the result and see whether there are any hotspots where Asian and Middle East population tend to live or any cold spots they are not present in.\n",
    "\n",
    "For easier reading we can relabel the quadrants with self-explanatory labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_labels = {\n",
    "    1: \"High-high\",\n",
    "    2: \"Low-high\",\n",
    "    3: \"Low-low\",\n",
    "    4: \"High-low\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can just assign the quadrants and P-value as columns, filter based on significance and look at the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa[\"moran_q\"] = moran_loc.q\n",
    "liv_lsoa[\"moran_q\"] = liv_lsoa[\"moran_q\"].map(moran_labels)\n",
    "liv_lsoa[\"moran_p\"] = moran_loc.p_sim\n",
    "liv_lsoa.loc[liv_lsoa[\"moran_p\"] > 0.05, \"moran_q\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.explore(\"moran_q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.explore(\"Middle East and Asia proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for yourself if we can see similar patterns for other demographic groups.\n",
    "\n",
    "## Going big\n",
    "\n",
    "We are entering the last part of the tutorial. This even may be a homework for you, depends on the time :).\n",
    "\n",
    "Everything we ave used so far was running in a single thread on your computers. Given you probably have 4 or more cores on your CPU, only one was running, other were idle.\n",
    "\n",
    "For these situations, and for those when your data don't fit your RAM, the Python ecosystem offers a solution called Dask-GeoPandas. What is Dask?\n",
    "\n",
    "From the docs:\n",
    "\n",
    "> Dask provides advanced parallelism and distributed out-of-core computation with a dask.dataframe module designed to scale pandas. Since GeoPandas is an extension to the pandas DataFrame, the same way Dask scales pandas can also be applied to GeoPandas.\n",
    "\n",
    "For more, see the [Dask tutorial](https://tutorial.dask.org).\n",
    "\n",
    "We use the powers of Dask and GeoPandas to run geospatial processing in parallel or even distrbuted and out-of-core.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That in practice means that we split the GeoDataFrame into multiple partitions and each is processed by a single thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_ddf = dask_geopandas.from_geopandas(liv_lsoa, npartitions=4)\n",
    "liv_ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is done lazily as Dask expects the data may be too large, we don't see the values here. For now.\n",
    "\n",
    "The API works nearly exactly the same as we have seen above. It is just split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perimeter = liv_ddf.length\n",
    "perimeter.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `compute()`, Dask runs all the tasks and returns the result. Same we would get from GeoPandas, just a bit faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = liv_ddf.compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How faster? Depends on the machine and operation, of course, but here is a simple example.\n",
    "\n",
    "The GeoDataFrame used above is a bit small to see any benefit from parallelization using dask (as the overhead of the task scheduler is larger than the actual operation on such a tiny dataframe), so letâs create a bigger point GeoSeries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "N = 10_000_000\n",
    "points = geopandas.GeoDataFrame(\n",
    "    geometry=geopandas.points_from_xy(numpy.random.randn(N), numpy.random.randn(N))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And creating the dask-geopandas version of this series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpoints = dask_geopandas.from_geopandas(points, npartitions=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single polygon for which we will check if the points are located within this polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.geometry\n",
    "\n",
    "box = shapely.geometry.box(0, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâs compare the time it takes to compute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit points.within(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit dpoints.within(box).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "This tutorial is more closely or more loosely based on the following resources:\n",
    "\n",
    "- [Introduction to GeoPandas](https://geopandas.org/en/latest/getting_started/introduction.html) by Martin Fleischmann and GeoPandas contributors\n",
    "- [Getting started (pandas)](https://pandas.pydata.org/docs/getting_started/index.html) by Stijn Van Hoey and pandas contributors\n",
    "- Arribas-Bel, (2019). A course on Geographic Data Science. Journal of Open Source Education, 2(14), 42, [https://doi.org/10.21105/jose.00042](https://doi.org/10.21105/jose.00042)\n",
    "- Fleischmann, M., Feliciotti, A. and Kerr, W. (2022), Evolution of Urban Patterns: Urban Morphology as an Open Reproducible Data Science. Geogr Anal, 54: 536-558. [https://doi.org/10.1111/gean.12302](https://doi.org/10.1111/gean.12302)\n",
    "- datos.gob.es [Administrative province boundaries in Catalonia](https://datos.gob.es/en/catalogo/a09002970-limites-administativos-provinciales-de-catalunya)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopython_tutorial",
   "language": "python",
   "name": "geopython_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d1b2c984ad473d756980598d6fae8279815dc9c89a9d51a262cfb04eba7ee8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
